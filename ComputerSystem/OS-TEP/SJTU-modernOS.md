# 现代操作系统 ： 原理与实现
## Chap 1: 操作系统概述
什么是操作系统：
* 硬件角度： 管理硬件， 对硬件提供抽象
* 软件角度： 服务于应用（提供接口， 访问控制，交互）， 管理应用（进程管理， 调度）

### 操作系统接口
从应用的角度， 操作系统提供了不同层次的接口：系统调用接口， POSIX 接口和领域应用接口。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220512111259.png" width="40%"/></div>  
* 应用程序通过操作系统内核提供的接口（如系统调用）向内核申请服务
* 由于每个操作系统提供的系统调用各不相同， 为了一个应用程序在不同操作系统上的可移植性， 形成了一些可移植的接口
* 在POSIX或操作系统调用的基础上还可以封装面向不同领域的领域应用接口

## Chap 4: 内存管理
为了使应用程序能够**高效**又**安全**地使用物理内存资源，现代操作系统的普遍做法是在应用程序和物理内存之间引入一个新的抽象：**虚拟内存**。虚拟内存在设计上有三个目标：
* **高效性**： 虚拟内存抽象不应能造成明显的性能开销， 也不应该占用过多的物理内存资源
* **安全性**： 抽象要使不同的应用程序互相隔离
* **透明性**： 应用程序开发者在编程时无需考虑虚拟内存抽象

### 虚拟地址与物理地址
逻辑上可以把物理内存看成一个大数组， 其中每个**字节**都通过与之唯一对应的地址（**物理地址**）进行访问。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220513104622.png" width="50%"/></div>  
应用程序使用虚拟地址访问存储在内存中的数据和代码，执行过程中， CPU 会将虚拟地址转换为物理地址（**地址翻译**），通过后者访问物理内存。  
**内存管理单元**(Memory Management Unit, MMU)负责虚拟地址到物理地址的转换，为了加速地址翻译的过程， 现代CPU都引人了**转址旁路缓存**（Translation Lookaside Buffer, TLB）， 它是 MMU 内部的单元。  

MMU 主要机制有两种：**分段机制**和**分页机制**。
* 分段机制下, 操作系统以“段”的形式管理、分配内存。应用程序的虚拟地址空间由若干个**不同大小的段**，比如代码段、数据段等， 组成。 MMU 会查询**段表**得到段对应的区域。
  * 段表存储着一个虚拟地址空间中每一个分段的信息，包括起始地址和段长
  * 虚拟地址由两部分组成：**段号**和**偏移量**
  * MMU首先通过**段表基址寄存器**找到段表的位置，结合段号得到段的起始位置， 加上偏移量得到物理地址<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220513164302.png" width="60%"/></div>
  * 这种方式容易导致在物理内存上出现**外部碎片**
* 分页机制基本思想是将应用程序的虚拟地址空间**划分成连续的、等长的虚拟页**，同时物理内存也被划分成连续的、等长的物理页帧。两者页长固定且相等，很方便为每个应用程序够造**页表**
  * 虚拟地址由两个部分构成：**虚拟页号** 和 **偏移量**
  * 页表起始地址存放在**页表基地址寄存器**中

### 基于分页的虚拟内存
简单页表（单级页表）我们根据虚拟页号找对应的数组项，其中的每一项都要存在（即使是没有用到的数组项）。对于 64 位虚拟地址空间， 假设页大小为 4kb,页表中每一项的大小为 8个字节，那么需要大小为 $2^{64-12} \times 8$ 字节（约 33 554 432GB)的页表。  
引入多级页表， 如果某一条目为空， 对应的下一级页表就无需存在， **极大减小的页表的空间占用， 同时允许结构中的空洞**。  
AArch64 结构下的 4级页表：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514003039.png" width="60%"/></div>
* 48-63 位： 全为 0 或者 1， 通常前者用于应用程序，后者用于系统程序
* 接下来每 9 位为一级页表

多级页表导致**地址翻译时间增加**，为了减少地址翻译中访存次数， MMU 引入**转址旁路缓存**（TLB),它缓存了虚拟页号到物理页号之间的映射关系， 可以将它理解为一个哈希表。  
类似于 CPU 缓存， TLB 硬件也采用分层结构：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514003901.png" width="50%"/></div>
* TLB 容量实际是很有限的， 依旧能保证较高的命中率， 是因为局部性起了重要的作用。

由于TLB 是使用虚拟地址进行查询的， 操作系统在进行页表切换（如应用程序切换）的时候需要主动刷新 TLB。刷新 TLB 后总是会发生 TLB 未命中从而带来性能损失， 一种解决方式是为 TLB 打上标签（如 AArch64 提供ASID,Address Space IDentifier）， 使得 TLB 中不同应用的缓存项被区分开。 
#### 换页与缺页异常
被分配使用的虚拟页**不一定有相应的物理页映射**， 因为存在**换页**机制： 当物理内存容量不够的时候，操作系统应该把若干物理页的内容写到类似于磁盘这种容量更大且更加便宜的存储设备中，然后就可以回收这些物理页并继续使用， 这个过程被称为**换出**(swap out)。  

**缺页异常**(page fault) 是换页机制能够正常工作的前提， 当应用程序访问已分配但未映射至物理内存虚拟页时触发， 此时 CPU 会运行系统预设的缺页异常处理函数(page fault handler), 函数会找到一个空闲页， 将之前写到磁盘的内容重新加载到物理页上， 并且在页表中填写虚拟地址到物理页面的映射， 这个过程称为 **换入**(swap in)。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514105014.png" width="60%"/></div>
缺页异常处理函数执行后， 代码又会回到触发异常的位置重新开始执行， 操作系统可以在不需要应用程序做任何修改的前提下（透明性）做出处理。换页还有两种优化方式：
* **预取**（prefetching）机制:发生换入操作时，预测还有哪些页即将被访问，提前将它们一并换入物理内存，从而减少发生缺页异常的次数
* **按需页分配**（demand paging）机制：当应用程序申请分配内存时，操作系统可选择将新分配的虚拟页标记成已分配但未映射至物理内存状态，而不必为这个虚拟页分配对应的物理页。

#### 页替换策略
在需要的时候， 操作系统根据**页替换策略**选择一个或一些物理页换出到磁盘以便让出空间。
* MIN: 优先选择未来最长时间内不会再访问的页
* FIFO： 选择最先换入的页进行换出
* Second Chance
* LRU: Least Recently Used,优先选择最久未被访问的页
* MRU: Most Recently Used, 优先换出最近访问的内存页
* 时钟算法策略

### 虚拟内存功能

## Chap 6: 操作系统调度
操作系统调度的目的是在有限的资源上， 通过对多个程序执行过程的管理， 尽可能满足系统和应用的指标(等待响应时间、完成时间、资源利用率、吞吐率...)。  
系统中的调度有很多类别，如 任务调度， I/O 调度，内存调度。这里主要关心的是任务调度， **进程是资源隔离的单位， 并不是执行的单位**， 一个进程可以有多个线程， 这些线程可以在不同的 CPU 核心上并行的地执行， 因此**线程才是调度器的调度对象**， Linux 中通常用==任务==(task)来描述线程。  
一般调度器通过维护==运行队列==(run queue) 的方式来管理任务， 它并非一定是一个 FIFO 队列（Linux 调度器使用红黑树实现）， 任务在触发一定条件会停止执行：
* 时间片耗尽
* 发起了 I/O 请求， 在 I/O 返回前不会继续执行
* 任务主动停止执行或者进入睡眠
* 任务被系统中断打断， 系统优先处理中断而暂缓执行

调度器设计的问题主要有两类：
* 调度器怎样做出决策？ 可以理解为调度指标是什么，如何考虑
* 调度器如何做出符合预期的决策

### 调度机制
进程可能处于不同的状态， 包括 **新生，就绪，运行， 阻塞**和**终止**。进程调度器根据职责不同分为长期、中期和短期调度。  
* 即使用户已经向操作系统提交了执行某个程序的请求，系统可能也不会立即处理该请求， 这个决策是由系统中的**长期调度**负责， 它像一个阀门，用于限制系统中真正被短期调度管理的进程数量，避免短期调度的开销过大。
* 当某个进程创建并被设置为 ready 之后， 就会由**短期调度**进一步管理该进程， 具体而言它主要负责进程在预备状态-运行状态-阻塞状态间的转换。
* 长期调度限制了进程数量， 但是使用内存仍然可能超过系统中内存总量， 这时候要由**中期调度**来负责， 它实际上是换页机制的—部分。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220511123051.png" width="70%"/></div>

### 单核调度策略


#### 调度指标
用户对于不同场景有不同的预期，常用的指标有几种类型：
* 与性能相关的**吞吐量,周转时间， 响应时间**
* 非性能指标 **公平性， 资源利用率**
* 特定场景的需求， 如终端设备的**能耗**， 实时任务的**实时性**

有的调度指标是和使用场景相关的：
* 有一类被称为批处理任务，如机器学习的训练， 执行时无需与用户交互，其目标就是尽可能快地完成,主要调度指标是任务处理的**吞吐量**（单位时间内处理的任务数量）尽可能高，调度需要让任务的**周转时间**（任务从被发起直至执行结束所需的时间）尽量短。  
* 计算机也要执行很多**交互式任务**， 如程序调试， 用户关心的是自己的请求（例如自己敲击键盘的输入）能否及时被处理， 这时候需要的是**响应时间**(任务从被发起直至第—次向用户返回输出以响应用户所需的时间)足够短，使用户获得良好的体验。  
* 在车载系统中， 系统还会被用于处理有截止时间要求的**实时任务**，在系统保证实时任务执行结果正确的同时，调度还必须让实时任务在截止时间前完成，即满足**实时性**。  
* 移动设备上的操作系统则尽可能降低**能耗**。  

而有的指标是所有场景共有的， 调度器应该尽可能地保证系统资源被充分利用，提高**资源利用率**； 在通常情况下, 应保证每个任务都有执行的可能, 即满足**公平性**; 调度器做出决策的时延应尽可能短, 降低**调度开销**。
### 调度机制

## Chap 8: 同步
并行处理同—任务意味着对共享资源的并发访问，为了保证共享资源状态的正确性,需要正确地在这些子任务之间进行同步。为此抽象出同步原语(synchronization primitive) 供开发者使用， 在单核中因为存在线程切换也存在多个线程之间同步的需求。
### 互斥锁
在生产者-消费者模型中， 如果两个线程同时写入缓冲区， 就会导致数据覆盖：**这种正确性依赖于特定执行顺序的情况被称为竞争冒险(race hazard)**。  
最直接的避免办法就是**确保同一时刻只有一个线程能够对缓冲区进行操作**， 又被称为 **互斥访问**(mutual exclusion), 而保证互斥访问共享资源的代码区域被称为**临界区**(critical section), 如何通过设计协议来保证互斥访问临界区的问题就称 **临界区问题**。需要设计一个协议来保证临界区的互斥性：<div align=center><img src="https://i.imgur.com/7tIqaeI.png" width="35%"/></div>  
设计的算法应该满足以下条件：
1. **互斥访问**:在同一时刻最多只有—个线程可以执们临界区
2. **有限等待**:当一个线程申请进人临界区之后，必须在有限的时间内获得许可并进入临界区，不能无限等待。
3. **空闲让迸**:当没有线程在执行临界区代码时， 必须在申请进人临界区的线程中选择一个线程，允许其执行临界区代码，保证程序执了的进展。

#### 硬件实现:互斥锁
在单核环境中， 我们可以通过关闭中断来解决临界区问题， 关闭中断**意味着当前执行的线程不会被其他线程抢占**。在多核环境中， 关闭中断并不能阻塞其他核心中正在运行的线程(恐龙书： 消息要传递到所有处理器，传递会延迟进入临界区，并降低系统效率)， 因此在多核环境中， 关闭中断依旧存在临界区问题。

#### 软件实现： 皮特森算法
皮特森算法中有全局数组 flag 和全局变量 turn,<font color=pink>这里的代码中都是将 turn 设置为对方而非自己</font>,否则会出现两个线程同时进入临界区的情况。<div align=center><img src="https://i.imgur.com/Ch9PGt5.png" width="70%"/></div>
皮特森算法只能适用于访存操作严格按照程序顺序执行的情况， 现代体系结构为了性能会允许访存操作的乱序执行， 无法使用皮特森算法。 

#### 软硬件协同： 使用原子操作实现互斥锁
我们还可以利用硬件提供的**原子操作**（atomic operation）设计新的软件算法来解决临界区问题。原子操作指的是不可被打断的—个或一系列操作，比较常见的有比较与置换(Compare And Swap, CAS)、拿取并累加(Fetch And Add, FAA) 等。