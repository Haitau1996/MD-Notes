# 现代操作系统 ： 原理与实现
## Chap 1: 操作系统概述
什么是操作系统：
* 硬件角度： 管理硬件， 对硬件提供抽象
* 软件角度： 服务于应用（提供接口， 访问控制，交互）， 管理应用（进程管理， 调度）

### 操作系统接口
从应用的角度， 操作系统提供了不同层次的接口：系统调用接口， POSIX 接口和领域应用接口。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220512111259.png" width="40%"/></div>  
* 应用程序通过操作系统内核提供的接口（如系统调用）向内核申请服务
* 由于每个操作系统提供的系统调用各不相同， 为了一个应用程序在不同操作系统上的可移植性， 形成了一些可移植的接口
* 在POSIX或操作系统调用的基础上还可以封装面向不同领域的领域应用接口

## Chap 4: 内存管理
为了使应用程序能够**高效**又**安全**地使用物理内存资源，现代操作系统的普遍做法是在应用程序和物理内存之间引入一个新的抽象：**虚拟内存**。虚拟内存在设计上有三个目标：
* **高效性**： 虚拟内存抽象不应能造成明显的性能开销， 也不应该占用过多的物理内存资源
* **安全性**： 抽象要使不同的应用程序互相隔离
* **透明性**： 应用程序开发者在编程时无需考虑虚拟内存抽象

### 虚拟地址与物理地址
逻辑上可以把物理内存看成一个大数组， 其中每个**字节**都通过与之唯一对应的地址（**物理地址**）进行访问。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220513104622.png" width="50%"/></div>  
应用程序使用虚拟地址访问存储在内存中的数据和代码，执行过程中， CPU 会将虚拟地址转换为物理地址（**地址翻译**），通过后者访问物理内存。  
**内存管理单元**(Memory Management Unit, MMU)负责虚拟地址到物理地址的转换，为了加速地址翻译的过程， 现代CPU都引人了**转址旁路缓存**（Translation Lookaside Buffer, TLB）， 它是 MMU 内部的单元。  

MMU 主要机制有两种：**分段机制**和**分页机制**。
* 分段机制下, 操作系统以“段”的形式管理、分配内存。应用程序的虚拟地址空间由若干个**不同大小的段**，比如代码段、数据段等， 组成。 MMU 会查询**段表**得到段对应的区域。
  * 段表存储着一个虚拟地址空间中每一个分段的信息，包括起始地址和段长
  * 虚拟地址由两部分组成：**段号**和**偏移量**
  * MMU首先通过**段表基址寄存器**找到段表的位置，结合段号得到段的起始位置， 加上偏移量得到物理地址<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220513164302.png" width="60%"/></div>
  * 这种方式容易导致在物理内存上出现**外部碎片**
* 分页机制基本思想是将应用程序的虚拟地址空间**划分成连续的、等长的虚拟页**，同时物理内存也被划分成连续的、等长的物理页帧。两者页长固定且相等，很方便为每个应用程序够造**页表**
  * 虚拟地址由两个部分构成：**虚拟页号** 和 **偏移量**
  * 页表起始地址存放在**页表基地址寄存器**中

### 基于分页的虚拟内存
简单页表（单级页表）我们根据虚拟页号找对应的数组项，其中的每一项都要存在（即使是没有用到的数组项）。对于 64 位虚拟地址空间， 假设页大小为 4kb,页表中每一项的大小为 8个字节，那么需要大小为 $2^{64-12} \times 8$ 字节（约 33 554 432GB)的页表。  
引入多级页表， 如果某一条目为空， 对应的下一级页表就无需存在， **极大减小的页表的空间占用， 同时允许结构中的空洞**。  
AArch64 结构下的 4级页表：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514003039.png" width="60%"/></div>
* 48-63 位： 全为 0 或者 1， 通常前者用于应用程序，后者用于系统程序
* 接下来每 9 位为一级页表

多级页表导致**地址翻译时间增加**，为了减少地址翻译中访存次数， MMU 引入**转址旁路缓存**（TLB),它缓存了虚拟页号到物理页号之间的映射关系， 可以将它理解为一个哈希表。  
类似于 CPU 缓存， TLB 硬件也采用分层结构：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514003901.png" width="50%"/></div>
* TLB 容量实际是很有限的， 依旧能保证较高的命中率， 是因为局部性起了重要的作用。

由于TLB 是使用虚拟地址进行查询的， 操作系统在进行页表切换（如应用程序切换）的时候需要主动刷新 TLB。刷新 TLB 后总是会发生 TLB 未命中从而带来性能损失， 一种解决方式是为 TLB 打上标签（如 AArch64 提供ASID,Address Space IDentifier）， 使得 TLB 中不同应用的缓存项被区分开。 
#### 换页与缺页异常
被分配使用的虚拟页**不一定有相应的物理页映射**， 因为存在**换页**机制： 当物理内存容量不够的时候，操作系统应该把若干物理页的内容写到类似于磁盘这种容量更大且更加便宜的存储设备中，然后就可以回收这些物理页并继续使用， 这个过程被称为**换出**(swap out)。  

**缺页异常**(page fault) 是换页机制能够正常工作的前提， 当应用程序访问已分配但未映射至物理内存虚拟页时触发， 此时 CPU 会运行系统预设的缺页异常处理函数(page fault handler), 函数会找到一个空闲页， 将之前写到磁盘的内容重新加载到物理页上， 并且在页表中填写虚拟地址到物理页面的映射， 这个过程称为 **换入**(swap in)。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514105014.png" width="60%"/></div>
缺页异常处理函数执行后， 代码又会回到触发异常的位置重新开始执行， 操作系统可以在不需要应用程序做任何修改的前提下（透明性）做出处理。换页还有两种优化方式：
* **预取**（prefetching）机制:发生换入操作时，预测还有哪些页即将被访问，提前将它们一并换入物理内存，从而减少发生缺页异常的次数
* **按需页分配**（demand paging）机制：当应用程序申请分配内存时，操作系统可选择将新分配的虚拟页标记成已分配但未映射至物理内存状态，而不必为这个虚拟页分配对应的物理页。

#### 页替换策略
在需要的时候， 操作系统根据**页替换策略**选择一个或一些物理页换出到磁盘以便让出空间。
* MIN: 优先选择未来最长时间内不会再访问的页
* FIFO： 选择最先换入的页进行换出
* Second Chance
* LRU: Least Recently Used,优先选择最久未被访问的页
* MRU: Most Recently Used, 优先换出最近访问的内存页
* 时钟算法策略

### 虚拟内存功能
* **共享内存**： 允许同一个页在不同的应用程序间共享<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514153416.png" width="50%"/></div>
* **写时拷贝**：很多场景下应用程序拥有相同的内存数据， 如加载相同的动态链接库， fork 出了子进程时两者内存数据和地址空间完全相同。写时拷贝**允许程序 A 和 B 以只读的方式共享同一段物理内存， 一旦应用程序对该区域进行修改就会触发缺页异常**，操作系统将物理内存中将对应的物理页拷贝一份， 将新拷贝的物理页以可读可写的方式重新映射给触发异常的应用程序， 然后再恢复执行。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514154643.png" width="50%"/></div>
* **内存去重**：操作系统可以定期地在内存中扫描具有相同内容的物理页,并且找到映射到这些物理页的虚拟页;然后只保留其中—个物理页，并将具有相同内容的其他虚拟页都用写时拷贝的方式映射到这个物理页，然后释放其他的物理页以供将来使用。
* **内存压缩**： 内存资源不充足的时候，操作系统选择一些“最近不太会使用”的内存页，压缩其中的数据，从而释放出更多空闲内存。当应用程序访问被压缩的数据时，操作系统将其解压即可，所有操作都在内存中完成。
* **大页**（huge page）机制能够有效缓解TLB缓存项不够用的问题，AArch64 体系结构 L2 页表项中存在一个特殊的位（第1位），它标识着这个页表项中存储的物理地址（页号） 是指向L3页表页（该位是1）还是指向一个2MB的物理页（该位是0）。如果 L1 的第一位是 0， 则表明指向一个大小为 1G 的大页。

### 物理内存的分配与管理
内存碎片指无法被利用的内存，它会直接导致内存利用率的下降
* **外部碎片**通常会在多次分配和回收之后产生，在多次分配和回收之后,物理内存上空闲的部分处于离散分布户的状态， 请求的内存可能大于任意一个单独的空闲部分而小于空闲部分的总和
* 当分配的内存空间大于实际分配请求所需要的空间时,就会造成部分内存的浪费，这种被浪费的内存空间即为**内部碎片**<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514203055.png" width="70%"/></div>

#### 伙伴系统
伙伴系统基本思想是将物理内存划分成连续的块,以块作为基本单位进行分配。不同块的大小可以不同，但每个块都由—个或多个连续的物理页组成，物理页的数量必须是2的 n 次幂($0 \leq n < max$, max 为预设的最大值)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220514205237.png" width="40%"/></div>  
当需要分配 m 个物理页时， 伙伴系统会找到大小合适的块， 包含 $2^n$ 个物理页， 且满足 $2^{n-1} < m \leq 2^{n}$。请求的时候， 大块可以分裂为两半，它们互称**伙伴**， 直到得到一个大小合适的块去服务分配请求。释放后分配器会寻找其他伙伴， 如果它们空闲则会合并。分裂和合并操作都是级联的，可以很好地缓解外部碎片的问题。  

#### SLAB 分配器
伙伴系统最小的分配单位是一个物理页（4KB），但是大多数情况下，内核需要分配的内存大小通常是几十个字节或几百个字节，远远小于—个物理页的大小， 这时候使用伙伴系统会带来严重的内部碎片问题。  
简单来说， SLAB 分配器做的事情就是把伙伴系统分配的大块内存进一步细分为小块内存进行管理。
* 操作系统频繁分配的对象大小相对固定
* 为了避免外部碎片问题， SLUB 分配器分配的固定大小的内存块大小通常为 $2^n$ 字节(通常$3\leq n<12$)， 程序员可以根据需要设置一些别的大小的内存块以减小内存碎片

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220515094224.png" width="70%"/></div>

SLUB 分配器向伙伴系统申请一定大小的内存块，并将获得的内存块作为一个 slab(内存块对应的数据结构):
* SLAB 会被划分成等长的小块内存， 内部空闲的小块内存会组织成空闲链表的形式
* 内存资源池包括 current 和 partial 两个指针， 前者指向一个 slab, 所有分配请求都从其指向的 slab 获得内存块， 后者指向拥有空闲块构成的 slab 链表
  * 得到一个分配请求后， 首先定位到**能满足请求大小且最接近的内存资源池**， 从 current 指向的 slab 拿出一块空闲块返回
    * current 不再有空闲块后， 从 partial 取出一个 slab 交给 current 指针， 没有的话则分配内存获得新的 slab
  * 接收到释放请求后， 放入其 slab 的空闲链表中， 
    * 如果 slab 空闲链表原来为空， 则将其添加到partial 指向的链表中
    * 如果释放后整个内存块都是空闲的， 则说明它可以释放并且交给伙伴系统

#### 常用的空闲链表
除了上面两种， 还有其他基于不同**空闲链表**的内存分配方法：
* 隐式空闲链表（implicit free list）：链表里的每个元素代表了一块内存区域，空闲（白色）和非空闲（彩色）的内存块混杂在同—条链表里<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220516001953.png" width="60%"/></div>
  * 请求时找到第一块够的内存块， 如果多了则分裂
  * 释放时检查前后是否空闲， 是的话则进行合并
* 显式空闲链表（explicit free list）:仅把空闲的内存块放在链表中<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220516002155.png" width="60%"/></div>
* 分离空闲链表（segregated free list）:维护多条不同的显式空闲链表,每条链表服务固定范围大小的分配请求<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220516002340.png" width="60%"/></div>

#### 物理内存与 CPU 缓存
操作系统在给应用程序分配物理页的时候， 如果能够分配尽量不会造成缓存冲突的物理页， 那么就可以使得尽可能多的应用数据存放到缓存中，从而充分利用缓存大小来提升应用访存性能。  
* 软件方案-染色机制：能够被存放到缓存中不同位置（不造成缓存冲突）的物理页标记上不同的颜色，在为连续虚拟内存页分配物理页的时候， 优先选择不同颜色的物理页进行分配<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220516002809.png" width="30%"/></div>
* 硬件方案-Intel CAT: 技术允许操作系统设置应用程序所能使用的最末级缓存的大小和区域,从而实现最末级缓存资源在不同应用程序间的隔离
* 硬件方案-ARMv8-A MPAM:支持配置多个分区ID（Partition ID, PARTID）并且限制每个 PARTID 能够使用的缓存资源

## Chap 6: 操作系统调度
操作系统调度的目的是在有限的资源上， 通过对多个程序执行过程的管理， 尽可能满足系统和应用的指标(等待响应时间、完成时间、资源利用率、吞吐率...)。  
系统中的调度有很多类别，如 任务调度， I/O 调度，内存调度。这里主要关心的是任务调度， **进程是资源隔离的单位， 并不是执行的单位**， 一个进程可以有多个线程， 这些线程可以在不同的 CPU 核心上并行的地执行， 因此**线程才是调度器的调度对象**， Linux 中通常用==任务==(task)来描述线程。  
一般调度器通过维护==运行队列==(run queue) 的方式来管理任务， 它并非一定是一个 FIFO 队列（Linux 调度器使用红黑树实现）， 任务在触发一定条件会停止执行：
* 时间片耗尽
* 发起了 I/O 请求， 在 I/O 返回前不会继续执行
* 任务主动停止执行或者进入睡眠
* 任务被系统中断打断， 系统优先处理中断而暂缓执行

调度器设计的问题主要有两类：
* 调度器怎样做出决策？ 可以理解为调度指标是什么，如何考虑
* 调度器如何做出符合预期的决策

### 调度机制
进程可能处于不同的状态， 包括 **新生，就绪，运行， 阻塞**和**终止**。进程调度器根据职责不同分为长期、中期和短期调度。  
* 即使用户已经向操作系统提交了执行某个程序的请求，系统可能也不会立即处理该请求， 这个决策是由系统中的**长期调度**负责， 它像一个阀门，用于限制系统中真正被短期调度管理的进程数量，避免短期调度的开销过大。
* 当某个进程创建并被设置为 ready 之后， 就会由**短期调度**进一步管理该进程， 具体而言它主要负责进程在预备状态-运行状态-阻塞状态间的转换。
* 长期调度限制了进程数量， 但是使用内存仍然可能超过系统中内存总量， 这时候要由**中期调度**来负责， 它实际上是换页机制的—部分。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220511123051.png" width="70%"/></div>

### 单核调度策略
#### 经典调度
* **先到先得**/先进先出（FIFS）- 简单直观，易于实现。弊端：
  * **在长短混合的场景下对短任务十分不友好**（护航效应）
  * 对 I/O 密集型任务不友好: 完成I/O 后无法立即执行， 下一轮 I/O 也会延后， 使得 I/O 资源的利用率低
* **最短任务优先**-在所有任务同时到达并且已知运行时间时是最优的，弊端：
  * 必须提前预知任务的运行时间
  * 其表现严重依赖于任务到达的时间点
* **最短完成时间优先**：上面两种是非抢占式调度（器必须等一个任务执行完或者主动退出执行才能升始下—个调度）， STCF是抢占式调度（可能会中断当前正在执行的任务）。它的一个弊端是**长任务饥饿**。
* **时间片轮转**：任务执行完时间片或者主动退出执行后， 切换到下一个任务，它的弊端在于**在运行时间相似的场景下的平均周转时间高**

#### 优先级调度

#### 调度指标
用户对于不同场景有不同的预期，常用的指标有几种类型：
* 与性能相关的**吞吐量,周转时间， 响应时间**
* 非性能指标 **公平性， 资源利用率**
* 特定场景的需求， 如终端设备的**能耗**， 实时任务的**实时性**

有的调度指标是和使用场景相关的：
* 有一类被称为批处理任务，如机器学习的训练， 执行时无需与用户交互，其目标就是尽可能快地完成,主要调度指标是任务处理的**吞吐量**（单位时间内处理的任务数量）尽可能高，调度需要让任务的**周转时间**（任务从被发起直至执行结束所需的时间）尽量短。  
* 计算机也要执行很多**交互式任务**， 如程序调试， 用户关心的是自己的请求（例如自己敲击键盘的输入）能否及时被处理， 这时候需要的是**响应时间**(任务从被发起直至第—次向用户返回输出以响应用户所需的时间)足够短，使用户获得良好的体验。  
* 在车载系统中， 系统还会被用于处理有截止时间要求的**实时任务**，在系统保证实时任务执行结果正确的同时，调度还必须让实时任务在截止时间前完成，即满足**实时性**。  
* 移动设备上的操作系统则尽可能降低**能耗**。  

而有的指标是所有场景共有的， 调度器应该尽可能地保证系统资源被充分利用，提高**资源利用率**； 在通常情况下, 应保证每个任务都有执行的可能, 即满足**公平性**; 调度器做出决策的时延应尽可能短, 降低**调度开销**。
### 调度机制

## Chap 8: 同步
并行处理同—任务意味着对共享资源的并发访问，为了保证共享资源状态的正确性,需要正确地在这些子任务之间进行同步。为此抽象出同步原语(synchronization primitive) 供开发者使用， 在单核中因为存在线程切换也存在多个线程之间同步的需求。
### 互斥锁
在生产者-消费者模型中， 如果两个线程同时写入缓冲区， 就会导致数据覆盖：**这种正确性依赖于特定执行顺序的情况被称为竞争冒险(race hazard)**。  
最直接的避免办法就是**确保同一时刻只有一个线程能够对缓冲区进行操作**， 又被称为 **互斥访问**(mutual exclusion), 而保证互斥访问共享资源的代码区域被称为**临界区**(critical section), 如何通过设计协议来保证互斥访问临界区的问题就称 **临界区问题**。需要设计一个协议来保证临界区的互斥性：<div align=center><img src="https://i.imgur.com/7tIqaeI.png" width="35%"/></div>  
设计的算法应该满足以下条件：
1. **互斥访问**:在同一时刻最多只有—个线程可以执们临界区
2. **有限等待**:当一个线程申请进人临界区之后，必须在有限的时间内获得许可并进入临界区，不能无限等待。
3. **空闲让迸**:当没有线程在执行临界区代码时， 必须在申请进人临界区的线程中选择一个线程，允许其执行临界区代码，保证程序执了的进展。

#### 硬件实现:互斥锁
在单核环境中， 我们可以通过关闭中断来解决临界区问题， 关闭中断**意味着当前执行的线程不会被其他线程抢占**。在多核环境中， 关闭中断并不能阻塞其他核心中正在运行的线程(恐龙书： 消息要传递到所有处理器，传递会延迟进入临界区，并降低系统效率)， 因此在多核环境中， 关闭中断依旧存在临界区问题。

#### 软件实现： 皮特森算法
皮特森算法中有全局数组 flag 和全局变量 turn,<font color=pink>这里的代码中都是将 turn 设置为对方而非自己</font>,否则会出现两个线程同时进入临界区的情况。<div align=center><img src="https://i.imgur.com/Ch9PGt5.png" width="70%"/></div>
皮特森算法只能适用于访存操作严格按照程序顺序执行的情况， 现代体系结构为了性能会允许访存操作的乱序执行， 无法使用皮特森算法。 

#### 软硬件协同： 使用原子操作实现互斥锁
我们还可以利用硬件提供的**原子操作**（atomic operation）设计新的软件算法来解决临界区问题。原子操作指的是不可被打断的—个或一系列操作，比较常见的有比较与置换(Compare And Swap, CAS)、拿取并累加(Fetch And Add, FAA) 等。