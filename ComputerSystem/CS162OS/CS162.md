# [CS162:Operating System and Systems Programming](https://inst.eecs.berkeley.edu/~cs162/fa20/)<!-- omit in toc -->

## Lecture 01: What is an operating system
因特网作为人类最伟大的创造，其组件在不同的时间尺度运行：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220110161033.png" width="60%"/></div>

操作系统是它们的核心：
* 使得基础技术的惊人进步可以用于快速演化的应用程序主体
  * 给应用程序提供了**一致的抽象**（consistent abstractions），即使面对不同的硬件
  * 在多个应用程序中管理**资源的共享**（sharing of resources）
* 主要的组成部分包括
  * 进程
  * 线程，并发，调度
  * 内存空间
  * ...

什么是操作系统？  
* 没有广泛接受的定义
* the kernel:the one program running at all times on the computer
  * 其他的东西要么是系统程序（和操作系统一起分发）要么是应用程序
* 一种定义： 是给应用程序提供硬件资源访问的特殊层级的软件
  * 给复杂的硬件提供便利的抽象
  * 提供共享资源受保护的访问
  * 安全和身份验证
  * 通信<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220112162937.png" width="40%"/></div>

如何才能称为是系统：
* 多个相互关联的部分
  * 每个部分可能和其他的相互作用
* 健壮性要求工程思维
  * 谨慎的错误处理
  * 把电脑当成是具体的机器， 考虑其限制和可能的错误

从软硬件接口的角度考虑：操作系统给应用程序提供硬件细节的抽象。
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220112164038.png" width="60%"/></div>
 
* 操作系统更像是一个魔术师,为物理资源提供简单易用的抽象
  * 无限的内存， 专用的机器（其实可能是共享的）
  * 高层级的对象： 文件、用户、消息
  * 掩盖限制， 虚拟化<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220112165238.png" width="80%"/></div>

  * 应用程序的“machine”实际上是 OS 提供的进程抽象
  * 每个运行中程序都在它自己的进程上运行
  * 进程提供比原硬件更好的接口
  * 进程是 OS 提供带有受限权力的执行环境，其中包含：
    * 地址空间：一块受保护的内存
    * 一个或者多个控制执行的线程
    * 其他与它关联的系统状态，如打开的文件， 打开的 sockets
* Referee(裁判， 仲裁者)
  * 管理 protection, isolation and sharing of resources<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220112171552.png" width="60%"/></div>
* Glue(胶水)
  * 提供 common services
  * 通常是通过库来提供

## Lecture 02: Four Fundamental OS Concepts
OS 抽象底层的硬件抽象以管理复杂性，<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220112234543.png" width="40%"/></div>

* 处理器 ➡️ 线程（thread）
* 内存 ➡️ 地址空间
* 硬盘 ➡️ 文件
* 网络 ➡️ Sockets
* 机器 ➡️ 进程（processes）

因此对于任意的 OS 领域，我们可以考虑下面两个问题：
* 需要应对怎样的硬件接口？ （physical reality）
* 需要提供怎样的软件接口？ （nicer abstraction）

四个重要的 OS 概念：
* 线程：执行的上下文
  * 完整描述程序的状态
  * 有程序计数器，寄存器， 执行标志，栈
* 地址空间(可能有翻译机制)
  * 程序可以获取的内存地址集合，
* 进程(process): 一个正在运行的程序实例
* 双模式操作、保护

指令的 fetch/Decode/Execute 循环：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113000129.png" width="40%"/></div>

### Thread of Control
* 线程是单个独立的执行上下文环境， 相当于上面的 fetch/decode/Execute loop 的虚拟化版本
* 当线程**驻留**(resident)在处理器寄存器中的时候， 它正在处理器中执行
* 驻留意味着寄存器持有该线程的根状态（上下文）
  * 包括了程序计数器(PC)寄存器 和正在执行的指令
    * PC 指向内存中要运行的下一条指令
    * 指令存放在内存中
  * 包括即将进行计算的立即数（可能是值本身或者指针）
  * 栈指针存放者栈顶的地址
  * 其他的线程则放在内存中
* 一个线程在没有加载到处理器中的时候被称为暂停(suspended)
  * 处理器的状态指向其他线程

从硬件的视角看程序的执行过程：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113001607.png" width="40%"/></div>

假设我们只有一个处理器， 我们应该怎样提供多出处理器的假象：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113002124.png" width="30%"/></div>
* 时分复用(multiplex in time)
* 线程实际上是虚拟的处理器<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113002307.png" width="40%"/></div>
* 因此线程（虚拟的处理器）中要有下面的内容：
  * PC, stack pointer
  * 寄存器
* 线程在哪里？
  * 运行在实际的内核中或者
  * 保存在一块内存中（被称为 TCB, Thread Control Block）
* 在线程之间切换的过程中， 发生了上下文切换
  * OS 正常运行
  * 将 PC,SP... 等放到 vCPU1 的 TCB 中
  * 从 vCPU2 的 TCB 中加载 PC,SP..., 跳转到 PC 的指令上
* 触发切换的机制
  * 计时器，voluntary yield, I/O ...

线程控制块（TCB）保存了线程不再运行时的寄存器内容， For now, 可以认为它们保存在 kernel 中。

### 地址空间
地址空间 👉 可访问的空间集 + 与之关联的状态。我们在地址上读写时， 很多事情都可能发生：
* 可能像正常的内存一样行为
* 可能忽略写操作
* 可能导致 I/O （memory-mapped I/O）
* 可能导致异常
* 可能和其他的程序通讯

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113005310.png" width="50%"/></div>
不同类型的数据放在地址空间的不同区域：

* 程序放置于 code segment 中
* 全局变量， 静态变量，字符串字面值等放置在 Static Data segment 中
* 局部变量放在 stack segment 中
* malloc 等调用产生的变量放置在 heap 中

过去简单的 multiprogramming 模型， 每个 thread 都可以读写内存（可能是其他 thread 的内存，也可能是 OS 的）， 这带来很高的风险。  
操作系统必须在用户程序面前保护自身：
* 可靠性： 损害操作系统的程序自身会崩溃
* 安全性： 限制 threads 可以做的范围
* 隐私性： 限制每个 thread 智能访问有权限的数据
* 公平性： 每个 thread 智能占有合理范围的计算机资源

OS 必须保证用户不受其他用户侵害：
* 保证一个用户的 threads 不会被其他用户的 threads 影响

#### 简单的保护： Base and Bound(B&B)
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113210947.png" width="60%"/></div>

Simple Protection 中用的依旧是物理地址， 加载的时候会做 address translation, 硬件会把指针和 base 和 bound 两个值做快速的比较。
* 提供了 OS 保护和程序的隔离
* 需要重定位加载器
* 地址路径上没有加法(addition)

#### 带有 Base 和 Bound 的简单地址转换
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113211900.png" width="60%"/></div>

* 硬件重定位
* 同样提供了 OS 保护和程序的隔离

#### 另一种思路： 地址空间转换
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113212233.png" width="50%"/></div>

更进一步的做法就是将整个虚拟地址空间分割成等尺寸的块(paged virtual address space)
* 所有的页都是相同的尺寸， 更方便地放在内存中
* 硬件使用**页表**(page table)来翻译地址
  * 每页有不同的 base
  * bound 就是页的大小
  * 特定的硬件寄存器可以存放页表的指针
  * 可以将内存当成是 page size 的帧， 可以将任意 page 放入任意帧<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113212910.png" width="80%"/></div>

### 进程
定义： 具有受限制权限的执行环境
* 有一个或者多个线程的受保护地址空间
* 自有的内存（地址空间）
* 自有的文件描述符， 文件系统内容
* 封装了一个或者多个**共享 process resources** 的线程

应用程序被当做进程执行：
* 复杂的程序可能 fork/exec 子进程

使用进程的原因：
* 进程间相互保护
* 保护 OS
* 进程提供了内存保护

进程权衡效率和保护
* 同一个进程间相互通讯比较容易
* 进程间的相互通讯要复杂很多

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113213812.png" width="50%"/></div>

* 线程封装了并发
  * 是主动的部件
* 地址空间封装了保护
  * 是被动的部件
  * 防止 buggy 程序损害操作系统
* 为什么在一个地址空间中要有多个 thread
  * 并行： 利用真实硬件的并行性
  * 并发： 方便同时处理 I/O 和其他事件

从机制上， 我们需要提供优先级， 不然一个进程可能改变自己的 page table pointer.

### 双模式操作
**硬件**提供最少两个模式（最小一个模式位，模式位的表示取决于具体的硬件）：
1. 内核态
2. 用户态

某些操作是禁止在用户态运行
* 更改页表指针、禁用中断、直接与硬件交互、写入内核内存 
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113214900.png" width="70%"/></div>

严格控制用户态和内核态之间的切换（仅限于系统调用，中断，异常），例如 unix 的系统结构：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113214944.png" width="70%"/></div>

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113215415.png" width="60%"/></div><div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113215505.png" width="60%"/></div>

有三种方式实现用户态到内核态的转换：
* 系统调用， 如进程要求系统服务(e.g., exit), 调用进程外的函数。。。
* 中断， 如 计时器，I/O 操作
* 异常或陷阱

## Lecture 03: Abstraction 1 - Threads and Processes, A quick Intro
这部分的主要目标是介绍 Thread 抽象：
* 什么是 thread
  * 什么不是 
* 为什么 thread 重要(motivation)
* 怎样使用 thread 编程
* thread 的替代品

### 上节回顾
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220113225909.png" width="60%"/></div>

前面提到的地址空间的概念， 其中的 translation map 由硬件的 MMU(Memory Management Unit)提供， 而操作系统负责它的配置(通过 Page Table)， 这种转换机制提供了保护功能, 因为程序无法访问其他程序和 OS 的存储空间。  
Process(进程) 是一个受保护的执行环境， 里面有一个或者多个 Thread(线程)， 它是一个 running program 实例， 使用进程是为了 protected from each other 同时 OS protected from them, 在现代操作系统中， 所有 kernel 外运行的程序都在进程中运行。  
双模操作： 进程在用户态运行， 而内核在内核态运行。我们需要严格控制两个模式之间的切换。  

### 什么是 thread
* 之前的定义：**单独的执行上下文**
* 它提供这样的抽象： 代表**独立可调度任务**的单个执行序列。
* threads 是一种并发机制(overlapping execution)
  * 此外它们也可以并行执行(simultaneous execution)
* 保护是和它无关的概念
  * 一个 protection domain 可能包含一个或者多个 thread

### thread 的动机
* 操作系统必须能够同时处理多个事情(multiple things at once, MTAO)
  * 进程， 中断， 后台的系统维护
* 网络服务器也必须处理 MTAO
  * 同时处理过个连接
* 并行程序必须处理 MTAO
  * 以实现更高的性能
* 有用户界面的程序经常需要处理 MTAO
  * 在进行计算时实现用户响应 
* 网路和硬盘相关的程序也应该处理 MTAO
  * 获取或者通信过程中有一系列的步骤，降低延迟

**Threads 可用于处理 MTAO**:
* 它是 OS 提供的并发单元
* 每个 threads 可以表示一个事情或者一个任务

和 multiprocessing 和 multiprogramming 相关的概念：
* Multiprocessing: Multiple CPUs(cores)
* Multiprogramming: Multiple jobs/processes
* Multi-threading: Multiple threads/processes<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114145020.png" width="60%"/></div>

我们写的并发程序要十分小心， 无论调度器如何处理都应该有正确的结果，因为 threads 并发执行意味着：
* **调度器可以自由地以任何顺序或交错运行线程**
* 线程可以执行到结束或者以大的代码块、小的代码块在时间切片中运行(不同的任务可能有重叠)

因此并发并不是并行：
* 并发是能够 handling multiple things at once (MTAO)
* 并行是能同时做多个事情(simultaneously)，如上图中任意时刻都有 A/B/C 三个程序的指令在执行
* 例如， 两个运行在一个 one-core 系统中的 thread 就是并发地执行， 但是不是并行
  * 每个 thread 处理一件事情
  * 但是两个 thread 并不需要 execute simultaneously 
    ```C++
    int main() {
      ComputePI(“pi.txt”);
      PrintClassList(“classlist.txt”);
    }
    int main() {
        create_thread(ComputePI, “pi.txt”);
        create_thread(PrintClassList, “classlist.txt”);
    }
    ```
    在第一个例子中， 因为 $\pi$ 的计算永远不会结束， 因此永远不会进入打印的函数。引入 thread 后， 调度器就可以让两个函数交替运行。
    * 给出有额外的 CPU 在运行第二个过程的错觉<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114150434.png" width="50%"/></div>

另一个实用的动机是 计算/IO 重叠：**在单独的线程中处理 IO 可以避免阻塞其他计算过程**。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114151254.png" width="50%"/></div>

#### Thread 屏蔽 I/O 延迟
一个 thread 至少有三种可能状态：
* running
* ready : 可以运行， 但是当下没有运行
* blocked: 无法运行

如果一个 thread 在等待 I/O 结束， 操作系统会将它标志为 BLOCKED, 一旦 I/O 完成， OS 会将它标志为 READY。
* 如果没有 IO: <div align=center><img src="https://i.imgur.com/fyE18uO.png" width="50%"/></div>
* 如果线程 1 进行了一个 IO 操作<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114151809.png" width="50%"/></div>

因此， 在涉及 I/O 或者需要大量计算的工作时候， 需要将它和需要快速响应的工作分开到不同的 threads 中：
```C++
int main() {
    create_thread(ReadLargeFile, “pi.txt”);
    create_thread(RenderUserInterface);
}
```
这样及时在进行长时间的 IO 操作， 系统依旧可以响应用户的输入。
### Multi-threaded 程序
通常编译器生成的可执行文件运行时， 进程的地址空间上最初只有一个线程，它在启动后可以通过系统调用创建一个新的线程， 这些线程共享同一个地址空间。相对的进程作为一种保护措施，进程键的information sharing 就困难很多，一般是通过进程间通信的。
#### 系统调用
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114154521.png" width="60%"/></div>

很多时候系统调用隐藏在编程的接口中
* 系统库提供 system call
* 编程语言的运行时使用系统库<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220114155009.png" width="50%"/></div>

#### OS 库的线程 API : pthread
* `int pthread_create(pthread_t *thread, const pthread_attr_t *attr,
                      void *(*start_routine)(void*), void *arg);`
    * 实际做的事情就是创建一个 thread, 然后使用 `arg` 为参数运行 `start_routine`，
    * 其中的 start_routine 是一个函数指针， 它的参数和返回值都是 void*。
* `void pthread_exit(void *value_ptr);`
    终止线程并且将 value_ptr 值可供 successful join 的线程访问
* `int pthread_join(pthread_t thread, void **value_ptr);`
  * 暂停调用端的执行直到目标线程终止

`pthread_create` 包装成一个普通的函数， 但是其中有在内核态执行的汇编代码：<div align=center><img src="https://i.imgur.com/gDRK95G.png" width="70%"/></div>

#### Fork-Join Pattern
<div align=center><img src="https://i.imgur.com/tCZ6vBM.png" width="40%"/></div>

我们使用一个小的[测试代码](Code/lec03/pthread_test.c)可以看到， 线程的很多状态在同一个进程/地址空间中是共享的：
* 内存中的内容(如 全局变量， 堆)
* IO 状态， 如文件描述符， 网络连接等

但是也有很多线程私有的状态：
* 存放在 TCB(Thread Control Block) 中的状态
* CPU 寄存器(包括 PC)
* 执行栈(Execution stack)
  * 参数， 临时变量
  * Return PCs<div align=center><img src="https://i.imgur.com/PREiRgh.png" width="50%"/></div>

这带来了新的问题， 不同线程的栈可能重合：<div align=center><img src="https://i.imgur.com/B4yHYpd.png" width="70%"/></div>

#### 并发下的正确性
<div align=center><img src="https://i.imgur.com/IAMV4gO.png" width="70%"/></div>

操作系统给提供了一个假象， 它拥有无穷多个处理器， 而实际上不同的线程在调度器下以不同的“速度”执行， 因此程序必须再任何调度下都可以正确运行。<div align=center><img src="https://i.imgur.com/omFwl7S.png" width="40%"/></div>

* 因此下面的事情是非确定性的：
  * 调度器可以以**任何顺序**运行线程
  * 调度器可以在**任何时候**切换线程
* 独立的线程
  * 和其他线程没有共享的状态
  * 确定性、可重复的条件
* 合作的线程
  * 多个线程间有共享状态

**竞态状态**：<div align=center><img src="https://i.imgur.com/TXYTX5u.png" width="40%"/></div>X 可能是 1，3，5(非确定的)。

几个相关的定义：
* 同步(Synchronization)：线程之间的协调，通常与共享数据有关。  
* 互斥([Mutual Exclusion](https://zh.wikipedia.org/zh-cn/%E4%BA%92%E6%96%A5%E9%94%81)):确保某个时刻只有一个线程做某件事情(一个线程排除其他的)
  * 它是同步的一种
* 临界区段（[Critical section](https://zh.wikipedia.org/zh-cn/%E8%87%A8%E7%95%8C%E5%8D%80%E6%AE%B5)）:一个访问共享资源的程序片段，而这些共享资源又无法同时被多个线程访问的特性。
  * 互斥的结果
* 锁： 在同一时间只能由一个线程持有的对象
  * 提供互斥

锁提供了两个操作：
* acquire(): 等待，直到锁被释放，然后将它标记为 busy。
  * 当它返回的时候，我们就认为线程持有这个锁
* release(): 将锁标记为 free<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220323183639.png" width="70%"/></div>

pthread 库中提供了锁：
* `int pthread_mutex_init(pthread_mutex_t *mutex,
                          const pthread_mutexattr_t *attr)`
* `int pthread_mutex_lock(pthread_mutex_t *mutex);`
* `int pthread_mutex_unlock(pthread_mutex_t *mutex);`<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220323184025.png" width="80%"/></div>

例如在上段代码的临界区段中， 先获取了 lock, 这时候线程持有了锁， 其他线程就无法进入修改 `my_common` 的值。如果获取的时候， 锁已经被其他线程持有， 那么线程就会休眠等待直到锁被释放。

### Bootstrapping(自举)
进程是由其他进程创建的， 而第一个进程是由内核创建的：
* 它通常被设置为内核启动前的参数
* 经常被叫做 "init" 进程

这个进程创建之后， 系统中的所有进程都是由其他进程创建。相关的接口如下：
* `exit()` – terminate a process
  * 如果没有显式调用， OS 库函数会帮我们调用，实际上可执行文件的入口也在 OS 库中， 然后 OS 库再调用 main 函数
* `fork()` – **copy the current process**，包括栈中的内容
  * 新进程有不同的 pid
  * 并且新进程包含单个线程
  * [fork()](Code/lec03/fork1.c) 中的所有值都是父进程的 copy,<font color=blue>包括文件描述符，地址空间等</font>,<font color=red>除了该函数的返回值</font>
    * 在新创建的子进程中该变量值为 0
    * 在调用端(父进程)中， 变量值为新创建进程的 pid<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220323190309.png" width="50%"/></div>
    * 地址空间是一个完全相当同的副本, 但是如果修改其中的值， 不会相互影响, 因为他们在不同的进程中,但是因为调度器可能有自己的调度策略， [示例代码中](Code/lec03/fork_race.c)打印的顺序是未定义的(有 `sleep()` 通常是交错输出，没有的话通常分别输出)
* `exec()` 执行一个新的程序： 我们可以在 fork 之后的新进程中执行别的程序, 例如一个 shell <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324190044.png" width="60%"/></div>
* `wait()`:等待一个进程结束
* `kill()`:send a signal (interrupt-like notification) to another process
* `sigaction()` – set handlers for signals,可以自定义中断处理[程序](Code/lec03/inf_loop.c),不同按键可以触发的信号：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324191310.png" width="70%"/></div>


## Lecture 04: Abstractions 2 - Files and I/O
### semaphores(信号量)：A quick Look
* 信号量是某种一般性的锁(generalized lock)
* 定义： 信号量有一个非负的整数， 它支持下面两种操作
  * P() or `down()`: 一种原子操作， 等待信号量变正， 然后将它减一
    * 可以将它视为是 wait 操作
  * V() or `up()`: 一种原子操作， 将信号量加一， 如果有任务在等待信号量, 将它唤醒
    * 可以将它视为是 signal 操作
  * 信号量像是一个整数，除开非负这个特性外， 它还只允许两个操作 P/V, 无法读取和赋值(除非在初始化时, POSIX 中可以读取， 但是技术上不认为是好的接口)
  * <font color=red> 信号量的操作是原子化的</font>

#### 两种模式
* Mutual Exclusion:(like lock)
  * 创建一个 binary semaphores or mutex
    ```C++
    initial value of semaphore = 1;
    semaphore.down();
        // 这是临界区段代码
    semaphore.up()
    ```
* Signaling 其他线程， 如下面的代码中， Join 部分并没有先运行， 而是等待 Finish 部分将信号量 +1 之后将它唤醒， 然后再给信号量 -1： <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324182432.png" width="70%"/></div>

### Unix/POSIX 理念： 所有东西都是文件
* 所有的东西都有相同的接口：
  * 硬盘上的文件
  * 设备(终端，鼠标指针等)
  * 网络(Sockets)
  * 进程间的通信(管道，Sockets)...
* 它们都基于几个系统调用`open()`/`read()`/`write()` 和 `close()`
* 附加的 `ioctl()` 以自定义不怎么匹配的事情(如屏幕分辨率等)

### 文件系统抽象
* 文件
  * Named collection of data in a file system
  * POSIX 中的 data: 字节的序列
  * 文件的元信息： 关于文件的信息， 包括大小，修改时间， 所有者等
* 目录
  * 包含了文件和目录的层次结构
  * 实际上就是 name 到实际文件内容的映射
* 每个进程都有当下工作目录， current working directory
  * 可以通过 `int chdir(const char* path)` 系统调用设置
  * 绝对路径 vs 相对路径(shell 中还有缩写 ~ 表示本用户目录， ~cs162 表示 cs162 的用户目录) 

从不同的层级看到的 I/O 也有一些区别：
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324214224.png" width="80%"/></div>

#### High-Level File I/O: Streams
* 流实际上是带有位置未格式化的字节序列(可能是纯文本或者二进制文件)带有位置<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324215112.png" width="40%"/></div>
    ```C
    #include<stdio.h>
    FILE *fopen(const char *filename, const char* mode);
    int fclose(FILE *fp);
    ```
* 打开的流是使用指向 FILE 结构体的指针表示(打开失败指针就为 NULL)
* 有三个 implicitly 打开的流， 标准输入输出和标准错误， 他们之间的组合可以使得进程之间通过管道这种链式的结构相互通信： `cat hello.text | grep "hello"`
* API(libc 的函数在 man-page 的第三部分): 
    ```C++
    // character oriented
    int fputc( int c, FILE *fp );
    // rtn c or EOF on err
    int fputs( const char *s, FILE *fp );
    // rtn > 0 or EOF
    int fgetc( FILE * fp );
    char *fgets( char *buf, int n, FILE *fp );

    // block oriented
    size_t fread(void *ptr, size_t size_of_elements,
                 size_t number_of_elements, FILE *a_file);
    size_t fwrite(const void *ptr, size_t size_of_elements,
                  size_t number_of_elements, FILE *a_file);

    // formatted
    int fprintf(FILE *restrict stream, const char *restrict format, ...);
    int fscanf(FILE *restrict stream, const char *restrict format, ... );
    ```
* 移动位置标识符<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220324221716.png" width="50%"/></div>
    ```C++
    int fseek(FILE *stream, long int offset, int whence);
    long int ftell (FILE *stream)
    void rewind (FILE *stream)
    ```

#### UNIX I/O 
Unix I/O 背后的设计理念：
* 统一性 ： everything is a file
  * 文件操作，设备 I/O, 进程间通信都通过 `open()`/`read()`/`write()` 和 `close()`
  * 允许程序的简单组合（find, grep, wc）
* 在使用之前要打开
  * 可以在打开的时候控制访问权限和属性
* Byte-Oriented
  * 即使是传输 blocks, 也是以 bytes 做寻址
* 内核会缓存输入输出， 磁盘是分块的，缓存可以帮助提高性能， 同时匹配设备的 block 结构

Unix I/O 的接口：
```C++
#include <fcntl.h>
#include <unistd.h>
#include <sys/types.h>
int open (const char *filename, int flags [, mode_t mode])
int creat (const char *filename, mode_t mode)
int close (int filedes)
```
其中的 flags 和 mode 都是 bit vector， 返回值是一个文件描述符。
* 文件描述符在内核中表示一个打开的文件实例
* 这是出于安全性的考虑，只给了一个数字就意味着你无法做超出权限的事情， 内核会用你提供的数字和内部的 entry 匹配， 文件描述符是线程私有的， 给一个随机数并没有用， 匹配失败则无法进行文件操作
* 文件描述符和 high-level 中的 FILE* 可以相互转换(`int fileno (FILE *stream)/FILE * fdopen (int filedes, const char *opentype)`)
* low-level 文件 API 和 high-level 基本对应
    ```C++
    ssize_t read (int filedes, void *buffer, size_t maxsize)
    ssize_t write (int filedes, const void *buffer, size_t size)
    off_t lseek (int filedes, off_t offset, int whence)
    ```

两个 API 的[对比](Code/lec04/high_vs_low.c)：
* low-level 只是系统调用的简单包装(Operations on file descriptors are visible immediately)
* high-level 做了额外的工作，如缓存等， 可以减少系统调用的次数(Streams are buffered in user memory)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325095115.png" width="80%"/></div><div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325101812.png" width="80%"/></div>
* FILE* 指向的结构体中有很多东西
  * 文件描述符， buffer, 锁...
  * 当我们调用 fwrite 时， 它会先写入 FILE 的 buffer, 如果 buffer 满了就会 flush(冲洗缓冲区)，也可以调用库函数手动缓冲
  * 写代码时候对缓冲区的冲洗做最低假设(不能依赖缓存满了自动冲洗的机制)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325101432.png" width="60%"/></div>

### 内核维护的状态
我们成功调用 `open()` 之后：
* 文件描述符(file descriptor) 会返回给用户
* 内核会创建关于打开文件的描述

对于每个进程， 内核都会维护从文件描述符到实际文件描述的映射。文件描述信息具体如下：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325112110.png" width="80%"/></div>

对于单个进程， 可以用下面的示意图来描述<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325112235.png" width="50%"/></div>  
如果我们使用 `fork()` 复制出一个新的进程:<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325112456.png" width="80%"/></div>

这意味着两者都可以访问那个文件，并且共享相同的文件描述。如果进程 1 关闭了文件， 进程 2 依旧持有该文件的描述， 终端模拟器就是一个很好的例子：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325112925.png" width="80%"/></div>

使用 `dup`/`dup2` 两个系统调用可以产生指向同一个文件描述的新文件描述符`open(“foo.txt”);read(3, buf, 100);dup(3);dup2(3, 162);`：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325113335.png" width="50%"/></div>

## Lecture 05: Abstractions 3 - IPC, Pipes and Sockets
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325114152.png" width="80%"/></div>
一个 web Server 的工作流程如下：
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220325163739.png" width="80%"/></div>

### 进程间通信
*  为什么需要进程间的通信？
  * 我们希望进程之间合作共同完成任务， 同时避免安全上的问题
* 实际上进程的设计是不鼓励进程间通信的
* 实现思路
  * 最简单的思路是通过文件来实现：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326162535.png" width="70%"/></div>
    * 但是这需要**付出非常高昂的代价**， 在硬盘读取过程中， 至少需要 1 million 的指令周期
  * 另一种思路是使用共享的内存<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326162110.png" width="70%"/></div>
  * 考虑像内核寻求帮助， 使用一个内存中的队列， 通过系统调用实现以保证安全<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326162349.png" width="70%"/></div>
    * A 写入的数据直到 B 读取完成之前都会存在于内存中
    * 和文件读写有相同的接口
    * 如果 A 写入得过快或者 B 读取得过快， 我们可以考虑 waiting
    * Unix 管道就是一个例子， 它有有限的缓存：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326163002.png" width="70%"/></div>
      * 如果 A 试图在缓存已经满的时候写入， it blocks(put to sleep until space)
      * 如果 B 在缓存空的时候读取， 它将被阻塞(put to sleep until data)
      * 系统调用`int pipe(int fileds[2])`: 从 `fileds[0]`读取， 写入到 `fileds[1]`, 例如， 我们可以先 fork, 然后分别将父进程和子进程的一端关闭：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326164124.png" width="70%"/></div>
      * 在管道中， 如果最后一个 "write" 文件描述符被关闭了(相当于是管道被关闭)， 这时候去读只能得到 `EOF`
      * 如果最后一个 "read" 文件描述符被关闭了， 写操作会产生 "SIGPIPE" 信号， 忽略它会引发“EPIPE” 错误

### 客户端-服务器协议：跨越网络的进程间通信
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326191508.png" width="70%"/></div>
上图中的每个客户端都有自己的 ip 地址和端口，所以通信的 channel 是独一无二的。

* client(客户) 一般只有某些时候在线， 
  * 在需要的时候向客户端发送请求，
  * 不和其他的客户端直接通信， 
  * 并且需要知道服务器的地址
* server 总是在线
  * 需要响应很多客户的请求
  * 不发起和客户端的通信(通信由客户端发起)
  * 需要一个固定并且广为人知的地址

网络连接实际上就是两个进程(可能在不同的机器上)的**双向字节流**(目前讨论的都是 TCP 协议下)， 抽象地理解，端点 A 和 B 之间的的连接包括：
* A 发送给 B 的字节队列(buffer 有限)
* B 发送给 A 的字节队列(buffer 有限)

而这种通信看上去就像是**File I/O**,<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326194753.png" width="70%"/></div>

* 上图的 Sockets 就是通信的端点(Endpoint)
  * 其中包含了存放临时文件的队列
  * 在任何类型的网络中都是同样的抽象， Local, the Internet and etc.
* 连接就是两个 Sockets 在网络上连接在了一起 ➡️ IPC over network

#### 套接字： More Details
* 看上去像是一个带有**文件描述符**的文件
  * 对应一个网络连接(有两个队列)
  * 向 Output 队列写入
  * 从 Input 队列读取
  * 有的操作不可用， 如 `lseek`
* 如何使用 Sockets 支持真实世界的应用？
  * 一个双向的字节流远远不够
  * 可能需要 messaging facility 来将 stream 分解成 chunks
  * 可能需要 RPC 工具来将一种环境转换为另一种环境，并通过网络提供函数调用的抽象

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326200636.png" width="90%"/></div><div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326200838.png" width="90%"/></div>

在上面的过程中， 我们做了一些假设：
* 可靠性， 向管道一样， 没有丢失
* 序列流是有序的
  * write X then write Y => read gets X then gets Y

#### 创建套接字
* 文件创建可以从根目录开始， 但是两个套接字并没有公共的祖先， 只有两个队列，如果给打开的套接字命名(标记)
* IP 通信中的 Namespace
  * Hostname (如 `www.eecs.berkeley.edu`)
  * IP address (IP v4 & v6)
  * 端口号(16个Bit)
    * 0~1023 是 well known 或者系统端口(绑定需要管理员权限)
    * 1024 - 49151 是登记端口
    * 后面的是动态或者私有的

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326202439.png" width="70%"/></div>
通常这样的一个连接有是一个 5 元素构成的元组： 源 ip 地址，目标 ip 地址， 源端口， 目标端口和通信协议(通常是 TCP)。 通常而言， 客户端的端口是随机的， 而服务端口是 well known 的(80 for web, 25 for mail sending and etc.)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326203144.png" width="80%"/></div>
上面的状态机模型还有一个小的问题就是一次只能有 1 个连接， 我们建立一个连接之后可以 fork 出一个子进程去处理相关的任务， 而自身仍可以监听连接：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326203612.png" width="90%"/></div>

#### 并发服务器
上面的 fork 中会为每次连接建立一个新的进程一个新的 socket, 可以使用一个新的线程去处理每个连接， 这样的话创建和切换线程都更加高效。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326204444.png" width="70%"/></div>
这样会带来一个新的问题就是线程数不受限制， 在网页变得更加 popular 之后可能带来新的问题， 这时候可以考虑使用线程池： 将新的 connection 入队， 当有空余的线程的时候再将队列头部弹出处理。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220326204749.png" width="70%"/></div>

## Lecture 06: Synchronization 1 - 并发和锁
### 进程复用 
#### 进程控制块(PCB)
* 在内核眼中每个进程以 PCB 的方式呈现， 它持有很多数据
  * 运行状态(running, blocked, ready)
  * 不运行时保存寄存器状态
  * 进程 ID, 用户， 优先级
  * 地址空间， 翻译 and etc. <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327092213.png" width="30%"/></div>
* 内核的调度器会持有包含这些 PCB 的数据结构， 以分配 CPU,做出 Policy Decision
* 内核也负责分配非 CPU 资源

#### 上下文切换
如果上下文切换过于频繁， 那么所有的CPU资源都用于额外开销，其中的内核态和用户态的切换可能带来昂贵的开销(寄存器状态保存到内存中，或者从内存恢复)：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327093246.png" width="70%"/></div>

#### 进程的生命周期
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327094015.png" width="70%"/></div>

在进程执行的各个阶段， 它可能会有下面不同的状态：
* new : 进程/线程 被创建了
* ready: 进程具备运行条件，但是在等待分配处理器以便运行
* running: 指令正在被执行
* waiting: 进程在等待其他事件完成， 在此之前不具备运行条件
* terminated: 进程的执行已经结束

### Scheduling
总的来说，PCBs 在不同的队列中移动， 而**调度器**决定它们的移动顺序<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327095521.png" width="70%"/></div>

ready 队列和不同的 I/O 队列： 如果一个进程没有在运行， 意味着它的 PCB 在某个调度队列中
* 不同的设备/信号/condition 有独立的队列
* 队列可以有不同的调度策略<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327140208.png" width="70%"/></div>

#### 并发的核心： Dispatch(分发) loop

* 概念上， 操作系统的调度循环就是不断地切换线程：
  ```Rust
  loop {
    RunThread();
    ChooseNextThread();
    SaveStateOfCPU(curTCB);
    LoadStateOfCPU(newTCB);
  }
  ```
* 这是一个无限循环，通常只有只有关机或者系统崩溃时候才停止

#### 运行一个线程
实现一个 `RunThread()` : 
* 怎样运行一个线程
  * 向 CPU 加载它的状态
  * 加载执行环境(地址空间 and etc.)， 调到 Program Counter
* 怎样重新获取控制器
  * 内部事件(internal events)： 线程自愿归还控制器
  * 外部事件(external events)： 线程被抢占

### 内部事件
* 被 I/O 阻塞： 请求 I/O 的过程实际上是会隐式通知 CPU
* 等待其他线程的信号： 线程请求等待也相当于是通知 CPU
* 线程执行 `yield()` 系统调用： 线程自动放弃 CPU 占用(pthread 也有相关 API `pthread_yield(void)`)

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327155416.png" width="40%"/></div>

需要注意的是我们陷入 OS 的时候， 需要更改运行的 stack(安全上的考虑)。在运行新的 Thread：
```C++
run_new_thread() {
    newThread = PickNewThread();
    switch(curThread, newThread);
    ThreadHouseKeeping(); /* Do any cleanup */
}
```
切换到新的线程时候， 需要保存所有可能被新线程损坏的东西， PC,regs, stack pointer,等等。 同时还要注意做好线程之间的隔离。  

#### Stack 图解
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327160434.png" width="85%"/></div>

实际上函数调用栈会来回切换， 是因为我们在上下文切换的代码中刚好改了pc 等寄存器的值， 然后相当于是跳进了另一个函数的调用栈， 依次返回弹出,例如我们从 S 线程调用 switch, 返回时候就进入了 T 线程。
```C++
Switch(tCur,tNew) {
    /* Unload old thread */
    TCB[tCur].regs.r7 = CPU.r7;
    …
    TCB[tCur].regs.r0 = CPU.r0;
    TCB[tCur].regs.sp = CPU.sp;
    TCB[tCur].regs.retpc = CPU.retpc; /*return addr*/
    /* Load and execute new thread */
    CPU.r7 = TCB[tNew].regs.r7;
    …
    CPU.r0 = TCB[tNew].regs.r0;
    CPU.sp = TCB[tNew].regs.sp;
    CPU.retpc = TCB[tNew].regs.retpc;
    return; /* Return to CPU.retpc */
}
```
* <font color=pink> TCP + Stack(User + kernel) 包含了线程完整的可重新开始启动的状态</font>
  * 可以将它放入任何队列中然后恢复
* 在实现 switch 中犯错，如忘记保存某个寄存器， 那么如果该状态未被使用则可能正常运行， 但是系统可能行为异常并且没有任何警告

一般而言上下文切换比切换进程成本要高昂很多， 在 Linux 中：
* 上下文切换的成本 10-100 ms
* 进程间切换的城北 3~4 $\mu$sec
* 切换线程的成本: 100 ns

在用户空间中使用 yield 切换线程就更加高效。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327162443.png" width="70%"/></div>
进程和线程相关成本的对比：
* 在单核的情况下 <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327162606.png" width="70%"/></div>
* 多核情况下 <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327162738.png" width="70%"/></div>

#### 线程被 I/O 阻塞
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327163254.png" width="40%"/></div>相当于是之前的 yield 换成了一个 I/O 操作， 依旧是同样的调用系统调用 ➡️ 初始化一个 I/O 操作 ➡️ 运行一个线程切换， 这时候线程进入 blocked 状态， 等 I/O 完成之后会进入 ready状态。  

### 外部事件
如果没有任何 I/O 和 yield ， 那么我么需要使用外部事件：
* 中断 ： 硬件或者软件终止正在运行的代码并且跳入内核的信号
* 计时器 ： 像一个闹钟一样定时（也是一种中断源）

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327164104.png" width="70%"/></div>

#### 初始化一个 TCB 和栈
1. 初始化 RCB 的寄存器域
   1. stack pointer 指向当前的栈
   2. PC 返回地址 => OS(asm) 程序 `ThreadRoot()`
   3. 两个参数寄存器初始化为 fcnPtr 和 fcnArgPtr
2. 栈数据则不需要初始化， 栈帧中重要的部分都在寄存器中<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327182550.png" width="50%"/></div>

这些工作昨晚之后， `run_new_thread()` 会选择这个新的 TCB 返回时候进入 `ThreadRoot()` 的起始位置， ThreadRoot 大致流程如下：
```C++
ThreadRoot(fcnPTR,fcnArgPtr) {
    DoStartupHousekeeping();
    UserModeSwitch(); /* enter user mode */
    Call fcnPtr(fcnArgPtr);
    ThreadFinish();
}
```

### 原子操作
原子操作指一个操作要么一次完成要么不运行，**不会被线程调度机制打断**。
* 在大多数机器上， 内存的引用和分配是原子化的
* 还有很多指令不是：
  * 双精度浮点的存储经常不是
  * VAX 和 IBM 360 有拷贝整个 array 的指令

线程间的切换可能导致程序错误：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327184131.png" width="60%"/></div>
这时候我们就需要原子操作告诉调度程序， 不同线程的 load->add->store 三个操作不能相互重叠。

这时候我们考虑 Lock，在进入临界区段前加锁， 然后离开时候释放， 过程中别的线程只能等待(<font color=pink>所有的同步操作都涉及等待</font>)。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327184928.png" width="70%"/></div>

**Synchronization**(同步)： 使用原子操作保证线程之间的合作。  
**Mutual Exclusion**(互斥)： 保证某个事情只有一个线程在处理， 即一个线程在处理某个资源时候排除其他线程的访问。  
在不加锁的情况下可能出现数据竞争：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327185859.png" width="60%"/><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327185945.png" width="70%"/></div>
但是如果锁没有加在合适的位置，依旧无法取得预想中的结果：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327190117.png" width="60%"/></div>

#### 有限缓存的生产者-消费者问题
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327191246.png" width="40%"/></div>

在上图所示的模型中， 有几个正确性的约束：
1. 在 buffer 为空的时候，消费者必须等待生产者填充 buffers
2. 在 buffer 满了之后， 生产者必须等待消费者消耗 buffer
3. **同时只有一个线程可以操作 buffer 队列**

使用下面的数据结构实现一个 buffer:<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328093210.png" width="60%"/></div>

使用锁的实现求解问题： 每次生产、消费前都请求加锁， 操作执行完再释放锁：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327192022.png" width="60%"/></div>这样就很可能产生死锁， 例如一个生产者加了锁， 然后队列已满，进入死循环， 而因为已经加了锁， 消费者就会一直等待。一个非常丑陋的改进方案是， 在无限循环中不断释放和加锁， 在单核和多核环境中都能正常工作， 但是其实的 busy waiting消耗了大量的 CPU 资源：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327192506.png" width="60%"/></div>
再回顾一下信号量(最早是从火车调度中引入)：
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327193652.png" width="60%"/></div>

信号量的两种用法：
  * 互斥(初始值为 1)， 也被称为 Binary Semaphore(二进制信号量)或者 mutex(互斥量)
  * 调度约束(初始值为 0)，例如我们想要线程 1 等待线程 2 的信号<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327194509.png" width="50%"/></div>

因为有三个约束条件， 我们考虑使用三个信号量(<font color=pink>每个约束要使用单独的信号量</font>)。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327195550.png" width="85%"/><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220327200053.png" width="70%"/></div>

## Lecture 07: Synchronization 2 - 信号量，锁的实现 和 原子指令
### Recall
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328091440.png" width="60%"/></div>
在任务状态段(Task-State Segment) 中有优先级栈，这时候如果系统调用/中断使得用户代码陷入内核代码， 这个过程是由硬件支持的：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328092619.png" width="80%"/></div>

### 进一步理解并发
一个新的例子，室友买牛奶：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328103935.png" width="70%"/></div>

这个问题的正确性在于两点：
1. 不要有超过 1 个人同时取买牛奶
2. 如果需， 有人会去买

*  解决方案 1： 使用一个 note 来避免买多了(降低了故障频率， 但是故障依旧会发生，即在检查和加锁的间歇切换线程)
     * 在买牛奶之前留下一个 note(像是某种锁)
     * 买完回来之后移除 note(释放锁)
     * 如果看到了 note 就不去买(等待)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328104506.png" width="50%"/></div>
* 解决方案 1.5： 在 check_milk 前加锁(**会导致死锁**)<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328105014.png" width="50%"/></div>
* 解决方案 2: 使用两个锁</div><div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328193457.png" width="50%"/></div>
    * 依旧会导致问题： 没有任何人去买牛奶(starvation)
* 解决方案 3： A B 线程使用不同的实现， 并且线程 A 中加了轮询。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328192716.png" width="50%"/></div>
  * 这个实现可以实现预期行为：在 X 处， 如果没有 noteB, A 购买是安全的， 否则就会一致轮询直到 B 做完相关的工作。 而在 Y 处， 如果没有 noteA, B 购买是安全的， 否则会 A 要么去购买要么等待 B 跳过并且移除 noteB.

### 锁的实现
一个 naive 的实现是用中断来实现锁：
* LockAcquire { disable Ints;}
* LockRelease { enable Ints;}

这种实有很大的问题：
* <font color=pink>不能让用户这么做</font>: 用户可能获取锁后进入死循环
* 在实时系统中， 这种做法没有任何时间上的保证： 临界区可能要消耗任意长的时间
* 还有可能会忽略 I/O 或者更重要的事件

更好的实现： 维持一个锁变量， 只有在操作那个变量的时候施加互斥。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328195044.png" width="60%"/></div>

在这种实现中， 我们<font color=green>有一个更短的临界区段</font>, 只是在禁止中断期间挪动线程所在的队列， 并没有实际运行线程。
* 这么做避免了在 check 和 set 锁值的时候被中断打断
* 否则有可能两个线程都认为他们持有这个锁<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328195943.png" width="50%"/></div>

我们实际来模拟两个线程工作的情况，可以看到， 当 A 持有锁并且没有释放之后， B 在 acquire 锁的过程中会被阻塞， 放入 waiting 队列：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328200539.png" width="85%"/></div>
并且线程 A 释放锁的时候， 因为 waiting-queue 不为空， 将 B 放入 ready-queue 的时候相当于直接转移锁的控制权， 直到 waiting queue 为空的时候才释放锁(value 重新设置为 0)。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328220344.png" width="85%"/></div>

## Lecture 08: 同步 3 - 原子指令，Monitors, Readers/Writers
首先， 我们不能把上节介绍的锁实现交给用户， 那么只能通过系统调用(开销相对较高)获取和释放锁。  
Alternative : **<font color=pink> atomic instruction sequences</font>**.下面是一些原子性指令序列的例子， 它们都将一次性执行完毕而不会在中途被调度器切换出去：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220328221644.png" width="60%"/></div>
* 这些指令可以原子性地读取和写入一个值
* <font color = pink>硬件 </font> 负责它的正确实现(在单核和多核上， 单核上相对简单， 后者可能需要缓存一致性协议的帮助)
* 禁止中断只能在单核上运行， 而原子指令序列可以在单核和多核上工作

### 实现
#### 使用 `compare&swap` 实现 Lock-Free 队列
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220329144238.png" width="80%"/></div>

大致的意思是说没有冲突的时候才做交换:
1. ld r1 M[root] 是将 root 的值读入寄存器 r1 中(temp = root)
2. st r1 M[object] 是将 r1 的值(root)写入 object (obj->next = temp)
3. 这时候 root地址的值依旧是 r1, 那么使用 object 覆写 root, 也就是说 root 指向新的节点

#### 使用 `test&set` 实现锁
```C++
// (Free) Can access this memory location from user space!
int mylock = 0; // Interface: acquire(&mylock);
                // release(&mylock);
acquire(int *thelock) {
    while (test&set(thelock)); // Atomic operation!
}
release(int *thelock) {
    *thelock = 0;// Atomic operation!
}
```
简单说明：
1. 如果 lock 是 free 的， 读取的值为 0 设置值为 1， 然后锁就变成了 busy 模式， 并且返回值是 0 循环就结束了
2. 如果锁是是 busy 的 ， 这时候去获取锁就是 busy-waiting, 那么所有的时钟周期都被浪费了
3. 释放锁之后， 切换到 busy-waiting 的线程， 它可以继续下一步， 同时获得了锁

这中实现可以在多核心上使用， 并且用户代码也可以使用锁， 不会影响系统中断， 但是有很大的问题：
1. 在循环等待的过程中消耗了大量的资源
2. 等待的线程不停地消耗时钟周期， 相当于是拖慢了持有锁线程的任务的执行
3. <font color=green>优先级反转</font>: 可能高优先级的任务在循环等待， 而低优先级的线程持有锁但是 CPU 份额少进展缓慢

#### 多处理器的自旋锁： `test&test&set`
```C++
// (Free) Can access this memory location from user space!
int mylock = 0; // Interface: acquire(&mylock); 
                //            release(&mylock);
acquire(int *thelock) { 
    do {
        while(*thelock);   // Wait until might be free (quick check/test!) 
    } while(test&set(thelock)); // Atomic grab of lock (exit if succeeded) 
}
release(int *thelock) {
*thelock = 0; // Atomic release of lock
}
```
这种实现有一个好处， 就是不用来回更新缓存， 但是它依旧有 busy-wait 的问题。

#### 更好的锁实现方式
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220329191725.png" width="80%"/></div>
这相当于是使用 `while(test&set(guard))` 去替换了单核系统中的禁止、恢复中断。最主要的想法就是， 线程在等待一个锁的时候， go to sleep, 这样的话就能很快跳出临界区段。

### Linux futex: fast userspace mutex
Linux 中的 futex 提供一种方法， 让线程等待直到某个值为 true。
```C++
#include<linux/futex.h>
#include<sys/time.h>
int futex ( int *uaddr, int futex_op, int val, 
            const struct timespec *timeout);
```
* futex_op 为 FUTEX_WAIT: 如果 val == *uaddr, 则线程等待直到 FUTEX_WAKE
* futex_op 为 FUTEX_WAKE: 叫醒不超过 val 个等待线程
#### T&S and futex
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220329193114.png" width="80%"/></div>  

* 使用了 futex(**没有busy-waiting**) 去实现 sleep 接口
* 获取 lock 时候没有开销
* 每次 unlock 时候需要系统调用去唤醒(即使是没有任何待唤醒任务)

#### T&S and futex 2
<div align=center><img src="https://i.imgur.com/1hVKNeN.png" width="80%"/></div>

另一个实现是让 lock 有三种状态：<div align=center><img src="https://i.imgur.com/Y0y7Bex.png" width="90%"/></div>

### 信号量很好， 但是 monitors 更好
**monitor**: 一种用于管理并发访问的数据结构， 包括一个锁和 0个或者多个条件变量。它是并发编程的一种模式。  
**条件变量**： 在 monitor 中， 条件变量是一个等待的线程队列， 等待临界区中的事件发生，它支持下面的操作：
* Wait(&lock) 原子性地释放锁并且进入睡眠状态，睡眠时持有 lock
* Signal(): 如果有等待线程的话， 唤醒一个
* Broadcast(): 唤醒所有等待线程

<div align=center><img src="https://i.imgur.com/btWl7Sd.png" width="80%"/></div>

这相当于是只有对消费者有限制的 half coke machine。

#### Mesa vs Hoare 管程
<div align=center><img src="https://i.imgur.com/obwUeOx.png" width="70%"/></div>
<div align=center><img src="https://i.imgur.com/NgGbzQ5.png" width="70%"/></div>

#### 生产者-消费者实现
<div align=center><img src="https://i.imgur.com/zSqa6to.png" width="70%"/></div>

#### 简单作者-读者问题
<div align=center><img src="https://i.imgur.com/Ha6NjqX.png" width="70%"/></div>

正确性约束：
1. 读者在没有作者的时候可以接入数据库
2. 作者在没有读者和作者的时候可以接入数据库
3. 一个时间段只有一个线程可以操作状态变量<div align=center><img src="https://i.imgur.com/9yAqlFE.png" width="70%"/></div>

<div align=center><img src="https://i.imgur.com/wqtxZtv.png" width="80%"/></div>
<div align=center><img src="https://i.imgur.com/RNmflQW.png" width="80%"/></div>

1. 在作者端，我们要先看有没有等待的其他作者， 因为作者通常数量远远小于读者， 而且读者总是倾向于要更新的数据， 因此优先唤醒其他作者。
2. 对于管程， 如果我们发出 signal 但是没有等待的线程， 那么 nothing happens。
## Lecture 09: 同步4 - 作者、读者问题，进程结构 & 设备驱动
### 模拟 R/W Solution
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407141022.png" width="70%"/></div>
来了一个读者， 这时候没有作者， 读者可以增加 AR 是因为它持有锁， 在临界区间中的操作是安全的。然后马上释放锁是为了允许更多的读者。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407141329.png" width="70%"/></div>
接下来 R2 进入， 在临界区段增加了 AR 后赋予访问权限， 这时候除了改变了 Active Reader 数量之外， 并没有改变其他东西， 锁还是 free的。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407141637.png" width="70%"/></div> 
来了一个作者， 因为 AW + WW > 0, 它会在条件变量出 sleep， 这个时候其实已经在 cond_wait 中释放了锁并且在将来唤醒时会重新获取， 所以可以认为在这个临界区间中一直持有锁，而在 sleep 时其他线程依旧可以申请锁。
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407142014.png" width="70%"/></div>
这时候再来一个读者， 发现有 Waiting Writer 或者 Active Writer, 更好的做法不是增加 Active Reader, 而是自己 sleep， 因为它的优先级其实是比作者低的。此时的状态如下：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407142242.png" width="70%"/></div>
接下来两个 Active Reader 进入下半部分， 依次减少 AR, 当 AR 为 0 并且有 Waiting Writer 时候将其中一个作者唤醒：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407142552.png" width="70%"/></div>
需要注意的是上面的 cond_wait 实际上会释放锁， 但是这里 signal 并不会， 会执行下一条释放锁的指令。 W1 会被唤醒（实际上是将 W1 放入 ready queue, 执行的时候依旧会检查锁的状态， 如果锁依旧不可获取， 它实际上会 sleep 等待锁， 而不再等待这个条件变量），执行后 AW+AR 为 0, 然后被赋予数据库访问权限：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407143533.png" width="70%"/></div>
写完之后会唤醒所有正在等待的 Reader, 这时候最高被唤醒的 Reader 会获取锁然后继续执行。

在这个循环中， 如果我们错误地提前唤醒了作者， 如丢了下面的语句， 在作者的 While-loop 中依旧会将它休眠， 只是要付出更高的调度成本：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407144220.png" width="70%"/></div>

如果只有一个条件变量，原来的调度可能有问题： <div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407144424.png" width="70%"/></div>
需要一些修改：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407144456.png" width="70%"/></div>

### 用信号量实现条件变量
* 锁的话很好实现： 使用一个 mutex
* 如果这样实现一个条件变量：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407144953.png" width="70%"/></div>
  * 可能在持有锁的情况下进入 sleep, 死锁
* 这样看起来能解决锁的问题<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407145059.png" width="70%"/></div>
  * 但是条件变量没有历史， 信号量有：
    * P and V are commutative – result is the same no matter what order they occur
    * Condition variables are NOT commutative
* 实际上可以正确实现， Hoare scheduling 复杂一些， 而  Mesa-scheduled solution 相对简单。

### 驱动
Recall: 内核结构<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407150426.png" width="70%"/></div>

//todo:文件读取：
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407180330.png" width="80%"/></div>

## Lecture 10: scheduling 1 - 概念和经典策略
操作系统很大部分的工作可以用下图来表示：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407181535.png" width="70%"/></div>

一个很自然的问题是， **操作系统是如何决定从就绪队列中取出一个来执行**，这个过程被称为 **调度**(scheduling)。  
在上世纪 70年代初因为大系统的需要开始研究调度的问题， 出于现实考虑当时有很多假设已经不符合现在的实际情况， 但是强的假设方便我们着手学习：
1. 一个用户只有一个程序
2. 每个程序使用一个线程
3. 程序之间是独立的

<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407182900.png" width="70%"/></div>

这里的 CPU burst time 是指CPU 开始执行到下次 IO 之间的时间， 执行模型： **程序在CPU 执行和 I/O 等待两个状态不断交换**，每次调度决定下一个 CPU 周期 CPU 运行哪个线程， 除了 I/O， 时间片用完后可能会强迫程序放起 CPU 占用。

评价调度的好坏有多个维度：
* 最小响应时间：**对某些特定的操作应该在最小的时间内完成**， 通常是响应用户能看到的任务
  * 通常会导致很多上下文切换， 开销非常大
* 最大吞吐量： 时间周期内能完成的操作（或者任务）最多
  * 通常和最小响应时间相反， 这里要求最小化开销（如上下文切换和相关的缓存重新建立），同时高效利用资源（CPU, 内存, etc.）
* 公平性：通常也和最小响应时间冲突， 早期有人会通过更多打印（要求响应时间短）来获得更多 CPU 资源

### First Come First Serve
也被称为 FIFO or Run Until done.<div align=center><img src="https://i.imgur.com/DEnYCtY.png" width="70%"/></div>

FCFS 调度是非抢占的，最大的问题是**护航效应**(convoy effect)， 先到一个 CPU周期长的任务， 然后队列中会有很多 CPU 周期短的任务一直等待：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407190055.png" width="70%"/></div>

### 轮转(Round Robin Scheduling)
这是一种抢占式的调度， 每个线程挨个获得一定的时间片（通常为 10-100 毫秒).
* 时间量用完之后， 将线程放回就绪队列的队尾
* 如果有 n 个线程， 时间量为 q, 获得下一个时间片的时间不超过 (n-1)*q.

性能分析：
1. q 非常大 -> 退化成 FCFS 调度
2. q 非常小 -> 开销很大
   1. 相对来说一定要比 context switch 大很多（通常上下文切换的开销有 0.1-1 毫秒，差不多占 1%）<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407191401.png" width="80%"/></div>

总的来说：
1. 对小的任务更好， 也提高了公平性
2. 长的任务会有很多上下文切换， 开销很大

对比 FCFS 和 RR：  
* 即使没有上下文切换的开销， 对于规模接近的任务，RR 效果也不是特别好：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407192238.png" width="80%"/></div>
* 此外 RR 中所有任务共享缓存状态， 而 FCFS 的缓存可以专注于一个任务
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407192656.png" width="80%"/></div>  
从中可以看到， 对于长的任务来说， 不同的调度对于等待时间和 完成时间影响不是特别大， 因此调度更多就是在不影响长任务的同时优化短任务的结果。

### 严格优先级调度(Strict Priority Scheduling)
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220407193342.png" width="50%"/></div>

执行计划：
* 总是执行最高优先级的任务直到运行结束
* 在每个队列中， 可以使用轮转处理

不足：
* 饥饿： 因为高优先级任务的存在， 第优先级任务总是得不到处理
* **死锁**： 优先级反转
  * 低优先级任务持有高优先级任务需要的锁，如果只有两个任务， 那么高优先级的任务进入阻塞队列， 也可以轮到低优先级任务执行并且释放所然后高优先级任务就绪
  * 通常会有第三个任务， 如这里在优先级 2 处有一个一致运行的任务， 6 持有 1 的锁， 则一致无法完成释放
  * 解决的办法就是**动态调整优先级**， 如 1 进入阻塞队列后可以把优先级捐赠给 6，或者任务的优先级在某个 base 上下调整

这种调度是不公平的， 我们可以通过某些策略调整
* 给不同的优先级分配一定的时间比例： 这时候可能有的优先级任务比较少， 需要调整不同优先级上的任务
* 给没有得到服务的任务提升优先级： Unix 很多分支都是这么做的

### 最短作业优先： 如果我们能预知未来
最短作业优先（Shortest Job First）和最短完成时间优先(shortest remaining time first),
//todo: 添加这部分笔记

## Lecture 11: 调度 2 - Case Studies, Real Time, and Forward Progress
//todo : 添加一些描述

### 多级反馈队列（Multilevel Feedback Queue）
<div align=center><img src="https://i.imgur.com/riiYstz.png" width="70%"/></div>

多级反馈队列是另一种基于历史行为的调度策略， 它有多个优先队列， 并且在不同的优先级上使用不同的调度方式：
* 高优先级被认为是前端的任务
* 不同优先级上可以有不同的调度策略， 如 foreground 使用轮转， background 使用 FCFS

并且我们可以调整优先级：
* 任务从最高优先级开始
* 如果时间片结束， 优先级下调
* 如果没有使用完时间片， 提升优先级（或直接提升到最高）

它实际上是对 SRFT 的一种预估：
* CPU 密集型任务会马上沉底
* 短时间运行、I/O 密集的认为总是在上面

在多个队列之间必须进行调度， 不然会有饥饿问题。
* 可以在不同的优先级之间切换
* 或者固定不同优先级的 CPU 份额

而这种调度会被用户利用，例如通过加入大量的 I/O 语句来获得 CPU 资源。

### Case Study： Linux O(1) 调度器
<div align=center><img src="https://i.imgur.com/RpTeisM.png" width="60%"/></div>

有 140 个优先级， 40个用于用户任务， 100 个用于“实时/内核”， 所有的算法都是 O(1) 的：
* 当任务执行完时间片， Timeslice/优先级/interactivity(交互) 等的贡献都会被计算

两个分开的优先队列： "active" 和 “expired”
* 所有活动的队列用完它们的时间片然后放入终止队列中， 这个过程全部结束， 交换队列

时间片的长度取决于优先级， 非常像多级反馈队列。<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220419214615.png" width="50%"/></div>
其中有很多需要试探（Heuristics）的东西：<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220419214750.png" width="70%"/></div>

很多的教科书使用旧模型，每个进程只有一个线程，但是 Linux 调度器实际调度的是线程而不是进程。它们之间有一个显著的区别：
* 切换线程： 保存、恢复寄存器
* 切换进程： 需要**更换活动的内存空间**， 相对昂贵， 因为缓存被打乱了

### 多核调度
* 从算法的角度， 多核调度和单核的调度没有大的区别
* 从实现的视角， 每个核心都有自己的调度数据结构更加方便
  * 缓存一致性问题
* 亲和性调度： 一旦某个线程被分配给一个 CPU, 操作系统尽量调度到这个 CPU 上
  * 缓存复用

### 实时调度
实时调度目标是**性能的可预测性**：
* 我们需要自信地预测最坏情况下系统的响应时间

硬实时：对于时间极其重要、安全导向的系统
* 满足所有的 deadline(如果可能的话)
* 理想条件下， 提前决定
* Earliest Deadline First, Least Laxity First, Rate-Monitonic Scheduling (RMS), Deadline Monotonic Scheduling (DM)

软实时： 通常是多媒体系统
* 把满足 deadline 放在高优先级
* Constant Bandwidth Server (CBS)

#### 实例研究
工作负载的特性：
* 任务是抢占性的， 相互独立并且在任意时间到达
* 任务有deadline 和已知的计算时间<div align=center><img src="https://i.imgur.com/oYDdIzr.png" width="70%"/></div>

显然轮转调度无法满足需求：<div align=center><img src="https://i.imgur.com/Zl7XyDL.png" width="70%"/></div>

**最早截止时间优先**（Earliest Deadline First， EDF）：
* 周期性的任务, 任务有周期（P） 每个周期需要的计算时间（C）， 用 $(P_i, C_i)$ 描述任务 i
* 抢占式基于优先级的动态调度：
  * 每个任务当前的优先级基于它距截止时间多近($D_i^{t+1} = D_i^t + P_i$)
  * 调度器总是让距离截止时间最近的任务运行<div align=center><img src="https://i.imgur.com/CTor4CJ.png" width="80%"/></div>
  * 如果系统没有过载， 那我们就能满足所有的 deadlines

在有很多任务的时候 EDF 可能无法工作， 但是如果 n 个任务满足下面的条件并且是抢占式的， 那么这些任务是可以调度的，并且 EDF 最优
$$
\sum_{i=1}^{n}(\frac{C_i}{P_i}) \leq 1 ,\text{其中 P 是周期， C 是计算时间}
$$

### 饥饿与死锁
**饥饿**： 线程无限期的周期中都没有取得进展
* 饥饿 $\neq$ 死锁: 饥饿在某些情况下是可以解决的， 而死锁是饥饿的一种，它不可解的，涉及环形的资源请求//todo: PPT 中的内容插入

优先级调度可能导致饥饿：
* 如果搞优先级的任务一直出现让系统过载， 低优先级的任务就会饥饿
* 更严重的问题是**优先级反转**：如高优先级的任务等待低优先级的任务释放其持有的锁<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504001803.png" width="50%"/></div><div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504001857.png" width="50%"/></div>
  * 这时候两个优先级中间的任务可能长时间运行， 这时候就让高优先级的任务也饥饿了， 相当于是**颠覆了我们设置的优先级**（中优先级的任务也可以让高优先级的饥饿）
  * 一个可行的做法是**优先级捐赠**：请求锁的任务将持有锁的任务优先级提升到自己的等级<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504002349.png" width="50%"/></div>

//todo : Key Idea: 比例分享调度
//todo : stride（步幅） scheduling PPT 内容

#### Case study: Linux Completely Fair Scheduling(CFS)
目标是每个进程都得到相同的 CPU 份额：
* N 个线程“同时” 在 $\frac{1}{N}$ 个 CPU 上执行
* 这个模型有点像是同时的超线程， 每个线程在时钟周期中得到 $\frac{1}{N}$<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504213408.png" width="50%"/></div>

在实际硬件中可能无法实现， 我们做法是**记录每个线程的 CPU 时间， 然后调度线程以匹配平均的执行比例**。
* 调度决策
  * 调整线程的运行实现完全公平的幻觉
  * 选择最小 CPU 时间的线程，尽量接近 Fair Queueing<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504213811.png" width="50%"/></div>
* 使用一个 heap-like 的调度队列
  * 添加、移除线程的时间复杂度为 $O(\log N)$ 
* 睡眠的线程 CPU 时间不会增加， 知道它们被唤醒

除了公平性问题， 我们还想要低响应时间和无饥饿（保证每个线程至少都能运行一点）
* 约束条件 1 ： 目标延迟
  * 每个进程都能得到服务的时间周期
  * 时间片 = target_Latency/n
  * 例如， 目标延迟 20ms, 4个进程， 每个进程都能得到 5ms 的时间片
  * 如果有 200个进程， 每个进程只有 0.1ms 的时间片， **时间片太小则上下文切换的开销过大**
* 约束条件 2： Minimum granularity(最小的时间片时间)
  * 如 target latency 20ms, 最小时间片 1 ms, 面对 200个进程
  * 这时候每个进程都有 1 ms 的时间片

优先级问题：在伯克利发挥在那操作系统时候， 优先级被称为 “be nice”, nice 值从 -20到 19
* 小的值是更不 "nice" 的
* 如果你想要让朋友有用更多时间， 提升自己任务的 "nice" 值(降低优先级)

* 这个值在 CFS 中可以转化为线程获得 CPU 资源的相对比例， CFS 更多像是一种比例分享的调度， **将权重 $w_i$ 赋予进程， 并在计算时间片中使用**：
  * 基础的比例分享 ： $Q_i = \text{Target Latency} \cdot \frac{1}{N}$
  * 带权重的共享： $Q_i = \text{Target Latency} \cdot \frac{w_i}{\sum_{p} w_j}$
* 我们可以从 nice 值得到一个权重， 而不是得到优先级
  * 低 nice value => 高优先级
  * $\text{Weight} = 1024/(1.25)^{\text{nice}}$
* CFS 调度时候记录线程的虚拟时间而不是物理时间<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504220754.png" width="70%"/></div>
  * 高权重的任务虚拟时间增加更慢
  * 低权重的任务虚拟时间证件更快
* 使用红黑树持有可执行的进程， 根据 vruntime 排序
  * 选择下一个运行的线程只需要 O(1) (在堆顶)
  * 插入、删除操作 $O(\log N)$
<div align=center><img src="https://raw.githubusercontent.com/Haitau1996/picgo-hosting/master/img/20220504221628.png" width="70%"/></div>

## Lecture 12: 调度3 - 死锁
